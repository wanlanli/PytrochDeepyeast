{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19b7627-b490-4349-8f0d-f06cab0f0eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liwa/miniconda3/envs/oneformer/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os, distutils.core\n",
    "sys.path.insert(0, os.path.abspath('../../../detectron2'))\n",
    "sys.path.insert(0, os.path.abspath('../../../'))\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "os.environ['DETECTRON2_DATASETS'] = '/home/liwa/data/datasets/'\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from oneformer.data.datasets.register_yeast_panoptic_annos_semseg import register_all_yeast_panoptic_annos_sem_seg\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd3134c2-d107-41d5-b5cd-8a684293cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.projects.panoptic_deeplab import (\n",
    "    PanopticDeeplabDatasetMapper,\n",
    "    add_panoptic_deeplab_config,\n",
    ")\n",
    "from detectron2.engine import default_setup\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from prediction import Predictor\n",
    "from google.colab.patches import cv2_imshow\n",
    "import os, json, cv2, random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45e9924-5695-4a92-9df0-281425e45a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.get_num_threads()\n",
    "torch.set_num_threads(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db9b462-5d60-4ef4-94ef-ea32a2d74d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:8700m\"\n",
    "cfg = get_cfg()\n",
    "add_panoptic_deeplab_config(cfg)\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(\"/home/liwa/data/oneformer_output/output/config.yaml\")\n",
    "\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "# into cpu model\n",
    "cfg.MODEL.SEM_SEG_HEAD.NORM = \"BN\"\n",
    "cfg.MODEL.INS_EMBED_HEAD.NORM = \"BN\"\n",
    "cfg.MODEL.RESNETS.NORM = \"BN\"\n",
    "\n",
    "\n",
    "# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "cfg.MODEL.PANOPTIC_DEEPLAB.TOP_K_INSTANCE = None\n",
    "cfg.MODEL.PANOPTIC_DEEPLAB.INSTANCE_AREA_THRESHOLD = 2000\n",
    "\n",
    "\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = os.path.abspath(\"/home/liwa/data/oneformer_output/output/model_0059999.pth\")\n",
    "# cfg.MODEL.WEIGHTS = \"detectron2://DeepLab/R-52.pkl\"\n",
    "# cfg.INPUT.MIN_SIZE_TEST = 512\n",
    "# cfg.INPUT.MAX_SIZE_TRAIN = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca7b8e5-7201-4445-a042-aae5b44f3f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'VERSION': 2, 'MODEL': CfgNode({'LOAD_PROPOSALS': False, 'MASK_ON': False, 'KEYPOINT_ON': False, 'DEVICE': 'cpu', 'META_ARCHITECTURE': 'PanopticDeepLab', 'WEIGHTS': '/home/liwa/data/oneformer_output/output/model_0059999.pth', 'PIXEL_MEAN': [102.364, 102.364, 102.364], 'PIXEL_STD': [23.532, 23.532, 23.532], 'BACKBONE': CfgNode({'NAME': 'build_resnet_deeplab_backbone', 'FREEZE_AT': 0}), 'FPN': CfgNode({'IN_FEATURES': [], 'OUT_CHANNELS': 256, 'NORM': '', 'FUSE_TYPE': 'sum'}), 'PROPOSAL_GENERATOR': CfgNode({'NAME': 'RPN', 'MIN_SIZE': 0}), 'ANCHOR_GENERATOR': CfgNode({'NAME': 'DefaultAnchorGenerator', 'SIZES': [[32, 64, 128, 256, 512]], 'ASPECT_RATIOS': [[0.5, 1.0, 2.0]], 'ANGLES': [[-90, 0, 90]], 'OFFSET': 0.0}), 'RPN': CfgNode({'HEAD_NAME': 'StandardRPNHead', 'IN_FEATURES': ['res4'], 'BOUNDARY_THRESH': -1, 'IOU_THRESHOLDS': [0.3, 0.7], 'IOU_LABELS': [0, -1, 1], 'BATCH_SIZE_PER_IMAGE': 256, 'POSITIVE_FRACTION': 0.5, 'BBOX_REG_LOSS_TYPE': 'smooth_l1', 'BBOX_REG_LOSS_WEIGHT': 1.0, 'BBOX_REG_WEIGHTS': (1.0, 1.0, 1.0, 1.0), 'SMOOTH_L1_BETA': 0.0, 'LOSS_WEIGHT': 1.0, 'PRE_NMS_TOPK_TRAIN': 12000, 'PRE_NMS_TOPK_TEST': 6000, 'POST_NMS_TOPK_TRAIN': 2000, 'POST_NMS_TOPK_TEST': 1000, 'NMS_THRESH': 0.7, 'CONV_DIMS': [-1]}), 'ROI_HEADS': CfgNode({'NAME': 'Res5ROIHeads', 'NUM_CLASSES': 9, 'IN_FEATURES': ['res4'], 'IOU_THRESHOLDS': [0.5], 'IOU_LABELS': [0, 1], 'BATCH_SIZE_PER_IMAGE': 512, 'POSITIVE_FRACTION': 0.25, 'SCORE_THRESH_TEST': 0.05, 'NMS_THRESH_TEST': 0.5, 'PROPOSAL_APPEND_GT': True}), 'ROI_BOX_HEAD': CfgNode({'NAME': '', 'BBOX_REG_LOSS_TYPE': 'smooth_l1', 'BBOX_REG_LOSS_WEIGHT': 1.0, 'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0), 'SMOOTH_L1_BETA': 0.0, 'POOLER_RESOLUTION': 14, 'POOLER_SAMPLING_RATIO': 0, 'POOLER_TYPE': 'ROIAlignV2', 'NUM_FC': 0, 'FC_DIM': 1024, 'NUM_CONV': 0, 'CONV_DIM': 256, 'NORM': '', 'CLS_AGNOSTIC_BBOX_REG': False, 'TRAIN_ON_PRED_BOXES': False, 'USE_FED_LOSS': False, 'USE_SIGMOID_CE': False, 'FED_LOSS_FREQ_WEIGHT_POWER': 0.5, 'FED_LOSS_NUM_CLASSES': 9}), 'ROI_BOX_CASCADE_HEAD': CfgNode({'BBOX_REG_WEIGHTS': ([10.0, 10.0, 5.0, 5.0], [20.0, 20.0, 10.0, 10.0], [30.0, 30.0, 15.0, 15.0]), 'IOUS': (0.5, 0.6, 0.7)}), 'ROI_MASK_HEAD': CfgNode({'NAME': 'MaskRCNNConvUpsampleHead', 'POOLER_RESOLUTION': 14, 'POOLER_SAMPLING_RATIO': 0, 'NUM_CONV': 0, 'CONV_DIM': 256, 'NORM': '', 'CLS_AGNOSTIC_MASK': False, 'POOLER_TYPE': 'ROIAlignV2'}), 'ROI_KEYPOINT_HEAD': CfgNode({'NAME': 'KRCNNConvDeconvUpsampleHead', 'POOLER_RESOLUTION': 14, 'POOLER_SAMPLING_RATIO': 0, 'CONV_DIMS': (512, 512, 512, 512, 512, 512, 512, 512), 'NUM_KEYPOINTS': 17, 'MIN_KEYPOINTS_PER_IMAGE': 1, 'NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS': True, 'LOSS_WEIGHT': 1.0, 'POOLER_TYPE': 'ROIAlignV2'}), 'SEM_SEG_HEAD': CfgNode({'NAME': 'PanopticDeepLabSemSegHead', 'IN_FEATURES': ['res2', 'res3', 'res5'], 'IGNORE_VALUE': 255, 'NUM_CLASSES': 9, 'CONVS_DIM': 256, 'COMMON_STRIDE': 4, 'NORM': 'BN', 'LOSS_WEIGHT': 1.0, 'LOSS_TYPE': 'hard_pixel_mining', 'PROJECT_FEATURES': ['res2', 'res3'], 'PROJECT_CHANNELS': [32, 64], 'ASPP_CHANNELS': 256, 'ASPP_DILATIONS': [6, 12, 18], 'ASPP_DROPOUT': 0.1, 'USE_DEPTHWISE_SEPARABLE_CONV': False, 'HEAD_CHANNELS': 256, 'LOSS_TOP_K': 0.2}), 'PANOPTIC_FPN': CfgNode({'INSTANCE_LOSS_WEIGHT': 1.0, 'COMBINE': CfgNode({'ENABLED': True, 'OVERLAP_THRESH': 0.5, 'STUFF_AREA_LIMIT': 4096, 'INSTANCES_CONFIDENCE_THRESH': 0.5})}), 'RETINANET': CfgNode({'NUM_CLASSES': 9, 'IN_FEATURES': ['p3', 'p4', 'p5', 'p6', 'p7'], 'NUM_CONVS': 4, 'IOU_THRESHOLDS': [0.4, 0.5], 'IOU_LABELS': [0, -1, 1], 'PRIOR_PROB': 0.01, 'SCORE_THRESH_TEST': 0.05, 'TOPK_CANDIDATES_TEST': 1000, 'NMS_THRESH_TEST': 0.5, 'BBOX_REG_WEIGHTS': (1.0, 1.0, 1.0, 1.0), 'FOCAL_LOSS_GAMMA': 2.0, 'FOCAL_LOSS_ALPHA': 0.25, 'SMOOTH_L1_LOSS_BETA': 0.1, 'BBOX_REG_LOSS_TYPE': 'smooth_l1', 'NORM': ''}), 'RESNETS': CfgNode({'DEPTH': 50, 'OUT_FEATURES': ['res2', 'res3', 'res5'], 'NUM_GROUPS': 1, 'NORM': 'BN', 'WIDTH_PER_GROUP': 64, 'STRIDE_IN_1X1': False, 'RES5_DILATION': 2, 'RES2_OUT_CHANNELS': 256, 'STEM_OUT_CHANNELS': 128, 'DEFORM_ON_PER_STAGE': [False, False, False, False], 'DEFORM_MODULATED': False, 'DEFORM_NUM_GROUPS': 1, 'RES4_DILATION': 1, 'RES5_MULTI_GRID': [1, 2, 4], 'STEM_TYPE': 'deeplab'}), 'INS_EMBED_HEAD': CfgNode({'NAME': 'PanopticDeepLabInsEmbedHead', 'IN_FEATURES': ['res2', 'res3', 'res5'], 'PROJECT_FEATURES': ['res2', 'res3'], 'PROJECT_CHANNELS': [32, 64], 'ASPP_CHANNELS': 256, 'ASPP_DILATIONS': [6, 12, 18], 'ASPP_DROPOUT': 0.1, 'HEAD_CHANNELS': 32, 'CONVS_DIM': 128, 'COMMON_STRIDE': 4, 'NORM': 'BN', 'CENTER_LOSS_WEIGHT': 200.0, 'OFFSET_LOSS_WEIGHT': 0.01}), 'PANOPTIC_DEEPLAB': CfgNode({'STUFF_AREA': 2048, 'CENTER_THRESHOLD': 0.1, 'NMS_KERNEL': 7, 'TOP_K_INSTANCE': 200, 'INSTANCE_AREA_THRESHOLD': 200, 'PREDICT_INSTANCES': True, 'USE_DEPTHWISE_SEPARABLE_CONV': False, 'SIZE_DIVISIBILITY': 512, 'BENCHMARK_NETWORK_SPEED': False}), 'IS_TRAIN': True, 'IS_DEMO': False}), 'INPUT': CfgNode({'MIN_SIZE_TRAIN': (0.5, 2), 'MIN_SIZE_TRAIN_SAMPLING': 'range', 'MAX_SIZE_TRAIN': 4096, 'MIN_SIZE_TEST': 512, 'MAX_SIZE_TEST': 2048, 'RANDOM_FLIP': 'horizontal', 'CROP': CfgNode({'ENABLED': True, 'TYPE': 'absolute', 'SIZE': [512, 512], 'SINGLE_CATEGORY_MAX_AREA': 1.0}), 'FORMAT': 'RGB', 'MASK_FORMAT': 'polygon', 'GAUSSIAN_SIGMA': 8, 'IGNORE_STUFF_IN_OFFSET': True, 'SMALL_INSTANCE_AREA': 0, 'SMALL_INSTANCE_WEIGHT': 1, 'IGNORE_CROWD_IN_SEMANTIC': False}), 'DATASETS': CfgNode({'TRAIN': ('yeastcity_train',), 'PROPOSAL_FILES_TRAIN': (), 'PRECOMPUTED_PROPOSAL_TOPK_TRAIN': 2000, 'TEST': ('yeastcity_val',), 'PROPOSAL_FILES_TEST': (), 'PRECOMPUTED_PROPOSAL_TOPK_TEST': 1000}), 'DATALOADER': CfgNode({'NUM_WORKERS': 10, 'ASPECT_RATIO_GROUPING': True, 'SAMPLER_TRAIN': 'TrainingSampler', 'REPEAT_THRESHOLD': 0.0, 'REPEAT_SQRT': True, 'FILTER_EMPTY_ANNOTATIONS': True}), 'SOLVER': CfgNode({'LR_SCHEDULER_NAME': 'WarmupPolyLR', 'MAX_ITER': 2000, 'BASE_LR': 0.0005, 'BASE_LR_END': 0.0, 'MOMENTUM': 0.9, 'NESTEROV': False, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_NORM': 0.0, 'GAMMA': 0.1, 'STEPS': (30000,), 'NUM_DECAYS': 3, 'WARMUP_FACTOR': 0.001, 'WARMUP_ITERS': 1000, 'WARMUP_METHOD': 'linear', 'RESCALE_INTERVAL': False, 'CHECKPOINT_PERIOD': 2000, 'IMS_PER_BATCH': 32, 'REFERENCE_WORLD_SIZE': 0, 'BIAS_LR_FACTOR': 1.0, 'WEIGHT_DECAY_BIAS': 0.0, 'CLIP_GRADIENTS': CfgNode({'ENABLED': False, 'CLIP_TYPE': 'value', 'CLIP_VALUE': 1.0, 'NORM_TYPE': 2.0}), 'AMP': CfgNode({'ENABLED': False}), 'POLY_LR_POWER': 0.9, 'POLY_LR_CONSTANT_ENDING': 0.0, 'OPTIMIZER': 'ADAM'}), 'TEST': CfgNode({'EXPECTED_RESULTS': [], 'EVAL_PERIOD': 0, 'KEYPOINT_OKS_SIGMAS': [], 'DETECTIONS_PER_IMAGE': 100, 'AUG': CfgNode({'ENABLED': False, 'MIN_SIZES': (400, 500, 600, 700, 800, 900, 1000, 1100, 1200), 'MAX_SIZE': 4000, 'FLIP': True}), 'PRECISE_BN': CfgNode({'ENABLED': False, 'NUM_ITER': 200})}), 'OUTPUT_DIR': '/home/liwa/data/oneformer_output/output', 'SEED': -1, 'CUDNN_BENCHMARK': False, 'VIS_PERIOD': 0, 'GLOBAL': CfgNode({'HACK': 1.0}), 'WANDB': CfgNode({'PROJECT': 'DeepLab', 'NAME': None})})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f01447-c9cd-42d8-b9e0-10a34df6c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread, imsave\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3748cd-871a-42d4-8ce8-fe9c422809bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a74d6c58-e373-42b5-8c02-0b5df8c89e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_path_list = list(Path(\"/home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/\").rglob(\"*_rigid.tif\"))\n",
    "movie_path_list = [str(x) for x in movie_path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fcd930a-9814-4a78-b4db-45b0b139e6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/20240427_yml21_44_amp_04_3_R3D_merge_rigid.tif',\n",
       " '/home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/20240427_yml21_44_amp_04_6_R3D_merge_rigid.tif',\n",
       " '/home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/20240427_yml21_44_amp_04_5_R3D_merge_rigid.tif',\n",
       " '/home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/20240427_yml21_44_amp_04_2_R3D_merge_rigid.tif']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d97bcaa-4073-4a81-9826-1df5470cb684",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = imread(movie_path_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de496e-d3b2-4aec-aab9-0cf045a63d23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/20240427_yml21_44_amp_04_3_R3D_merge_rigid.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/881 [00:00<?, ?it/s]/home/liwa/miniconda3/envs/oneformer/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180588308/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|█████████████████████████████████████| 881/881 [42:01:32<00:00, 171.73s/it]\n",
      "/tmp/ipykernel_3336414/816345210.py:14: UserWarning: /home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/20240427_yml21_44_amp_04_3_R3D_merge_rigid_mask.tif is a low contrast image\n",
      "  imsave(movie_path[:-4]+\"_mask.tif\", segment_movie)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/20240427_yml21_44_amp_04_6_R3D_merge_rigid.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 881/881 [41:53:37<00:00, 171.19s/it]\n",
      "/tmp/ipykernel_3336414/816345210.py:14: UserWarning: /home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/20240427_yml21_44_amp_04_6_R3D_merge_rigid_mask.tif is a low contrast image\n",
      "  imsave(movie_path[:-4]+\"_mask.tif\", segment_movie)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/20240427_yml21_44_amp_04_5_R3D_merge_rigid.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 881/881 [42:41:56<00:00, 174.48s/it]\n",
      "/tmp/ipykernel_3336414/816345210.py:14: UserWarning: /home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/20240427_yml21_44_amp_04_5_R3D_merge_rigid_mask.tif is a low contrast image\n",
      "  imsave(movie_path[:-4]+\"_mask.tif\", segment_movie)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/liwa/data/mating_data/patch/20240427_hm_scd2_hp_scd2/20240427_yml21_44_amp_04_2_R3D_merge_rigid.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████████████████████████████████████████████▋                                                                                  | 422/881 [20:26:56<22:05:21, 173.25s/it]"
     ]
    }
   ],
   "source": [
    "for movie_path in movie_path_list:\n",
    "    print(movie_path)\n",
    "    movie = imread(movie_path)\n",
    "    segment_movie = np.zeros(movie.shape[:3], dtype=np.uint16)\n",
    "    for frame in trange(0, movie.shape[0]):\n",
    "        image = movie[frame,:,:,0]\n",
    "        image = image - image.min()\n",
    "        image = image / image.max()\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        im = np.stack((image,)*3, axis=-1)\n",
    "        prediction_output = predictor(im)\n",
    "        panoptic_seg, _ = prediction_output[\"panoptic_seg\"]\n",
    "        segment_movie[frame] = np.array(panoptic_seg)\n",
    "    imsave(movie_path[:-4]+\"_mask.tif\", segment_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc62b729-253c-462d-8b0e-76fdbecd271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2980070/708227417.py:1: UserWarning: /home/liwa/data/mating_data/patch/20240607_2scd2_gfp_002/1_rigid_mask.tif is a low contrast image\n",
      "  imsave(movie_path[:-4]+\"_mask.tif\", segment_movie)\n"
     ]
    }
   ],
   "source": [
    "imsave(movie_path[:-4]+\"_mask.tif\", segment_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e2b83-d83b-4529-b98f-05b6eeccca01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89d9aa-c76a-4b1f-ae80-4a3f48e517f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355ef05-7428-41f1-afdf-115ddea32d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b17ba9cf-2182-4bb9-95f9-e89195ed46a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = imread(\"./00087-1.png\")\n",
    "# segment_movie = np.zeros(movie.shape[:3], dtype=np.uint16)\n",
    "# for frame in trange(0, movie.shape[0]):\n",
    "#     image = movie[frame,:,:,0]\n",
    "#     image = image - image.min()\n",
    "#     image = image / image.max()\n",
    "#     image = (image * 255).astype(np.uint8)\n",
    "#     im = np.stack((image,)*3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665d3ca-48d7-4422-ae8d-6f5c2224a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liwa/miniconda3/envs/oneformer/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180588308/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "prediction_output = predictor(im)\n",
    "print(prediction_output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f441f10f-74d5-470a-851f-5c9761f18d96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m panoptic_seg, segments_info \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_output\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpanoptic_seg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m v \u001b[38;5;241m=\u001b[39m Visualizer(im[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], MetadataCatalog\u001b[38;5;241m.\u001b[39mget(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTRAIN[\u001b[38;5;241m0\u001b[39m]), scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m out \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mdraw_panoptic_seg_predictions(panoptic_seg\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m), segments_info)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction_output' is not defined"
     ]
    }
   ],
   "source": [
    "panoptic_seg, segments_info = prediction_output[\"panoptic_seg\"]\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1)\n",
    "out = v.draw_panoptic_seg_predictions(panoptic_seg.to(\"cpu\"), segments_info)\n",
    "cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165aa3f2-213d-4fb8-ae63-ce746e25d831",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'panoptic_seg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpanoptic_seg\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'panoptic_seg' is not defined"
     ]
    }
   ],
   "source": [
    "panoptic_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa101ed6-1991-45ee-97b5-d9befac740ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff92b37-336e-4383-bf87-fe77c80cf56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0f768-2f6d-44a4-b792-830a924c2897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488a492-548c-4f7d-837f-82c21bf96c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
